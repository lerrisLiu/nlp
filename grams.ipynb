{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "import nltk\n",
    "\n",
    "jieba.load_userdict('define.txt') \n",
    "#stop_words\n",
    "def stopWords(stop_words):\n",
    "    f=open(stop_words).readlines() \n",
    "    stop_words=[i.strip().replace('\\n','') for i in f ]\n",
    "    return stop_words\n",
    "\n",
    "#text cut\n",
    "def split_words(x):\n",
    "    tokens=[word for word in jieba.cut(x) if word not in stop_words and word not in ['\\n',' ']]\n",
    "    return tokens\n",
    "\n",
    "#grams\n",
    "def cal_grams(word_list,n):\n",
    "    grams=nltk.ngrams(word_list,n)\n",
    "    return grams\n",
    "\n",
    "#cal dict\n",
    "def cal_dict(data,n):\n",
    "    word_freq={}\n",
    "    data=open(data,encoding='utf-8').readlines()\n",
    "    for text in data:\n",
    "        word_list=split_words(text)\n",
    "        grams=cal_grams(word_list,n)\n",
    "        try:\n",
    "            for group in grams:\n",
    "                a,b=group[0],''.join(group[1:])\n",
    "                word_freq.setdefault(a,{})\n",
    "                if b not in word_freq[a]:\n",
    "                    word_freq[a][b]=0 \n",
    "                else:\n",
    "                    word_freq[a][b]+=1 \n",
    "        except:\n",
    "            #print('空列表')\n",
    "            continue\n",
    "    return word_freq\n",
    "\n",
    "#word recommend\n",
    "def word_rec(d,p):\n",
    "    word_top={}\n",
    "    for k,w in d.items():\n",
    "        words_sort=sorted(w.items(),key=lambda x:x[1],reverse=True)\n",
    "        words_sort=[word[0] for word in words_sort if word[0] not in ['\\n',' ']][:p]\n",
    "        if len(words_sort)>0:\n",
    "            word_top[k]=words_sort\n",
    "    return word_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'查询': ['寿险', '车险'],\n",
       " '寿险': ['分公司'],\n",
       " '分公司': ['电话'],\n",
       " '电子': ['发票'],\n",
       " '发票': ['打印'],\n",
       " '保单': ['丢', '查询'],\n",
       " '丢': ['补'],\n",
       " '车险': ['投保', '报价'],\n",
       " '投保': ['信息'],\n",
       " '平安': ['车险', 'e生保'],\n",
       " '报价': ['查询'],\n",
       " 'e生保': ['买'],\n",
       " '公司': ['团体'],\n",
       " '团体': ['商业险'],\n",
       " '商业险': ['购买', '保费', '保单数'],\n",
       " '小学生': ['购买'],\n",
       " '在线': ['续保'],\n",
       " '本月': ['保额', '保单', '总保额', '上半月', '每日'],\n",
       " '保额': ['累计'],\n",
       " '去年': ['累计', '购买', '保单', '总保单', '天数'],\n",
       " '累计': ['天数', '保额'],\n",
       " '昨日': ['保额', '保单', '保费'],\n",
       " '总保单': ['销量'],\n",
       " '购买': ['人数'],\n",
       " '上海地区': ['保单'],\n",
       " '上半月': ['保额'],\n",
       " '每日': ['保单量'],\n",
       " '半年': ['每月'],\n",
       " '每月': ['保费'],\n",
       " '交强险': ['保费', '保单'],\n",
       " '新保': ['车辆'],\n",
       " '出单': ['趋势'],\n",
       " '单量': ['分布'],\n",
       " '续保': ['车辆数']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words=stopWords('stop_words.txt')  #读取停用词表\n",
    "word_freq=cal_dict('questions.txt',2)  #计算每个词接下来的3-grams词汇和对应的词频\n",
    "word_top=word_rec(word_freq,5) #选出最有可能出现的10个组合\n",
    "word_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
